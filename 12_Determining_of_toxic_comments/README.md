# Определение токсичных комментариев
## Описание проекта

<br>Для анализа данных и построения модели предоставлен датасет с размеченными данными, содержащий комментарии пользователей к товарам, доступным для приобретения в интернет-магазине. Датасет состоит из 2 столбцов с данными и 159571 строк.
<br>Проект завершен.

## Цель проекта
- Построить модель для определения "токсичных комментариев";
- Достичь требуемого показателя метрики F1

## Ход выполнения проекта
На первом этапе произведена загрузка данных и их подготовка для обучения моделей.
<br>После открытия датасета и ознакомления с общей информацией объявлен корпус текстов и переведен в тип юникод. Затем тексты были очищены и лемматизированы.
<br>Проверка соотношения классов показала, что в датасете имеет место явный дисбаланс. Мажорный класс составляет лишь 10% от всего датасета. Следовательно этот аспект необходимо будет учесть при обучении моделей.
<br>Для векторизации текстов был использован TfidfVectorizer(). После векторизации датасет  образовал матрицу размером 159571 строк на 164272 столбцов.

<br>Полученный датасет разделен на обучающую и тестовые выборки в соотношении 4:1.
<br>По результатам подбора гиперпараметров и обучения моделей наилучший результат показал Катбуст классификатор, наихудший - Случайный лес. Все выбранные модели прошли проверку на адекватность в сравнении с константной моделью. Для определения качества предсказания использована метрика F1.

## Итоги проекта
- Построена модель для определения "токсичных комментариев";
- Получено требуемое значение метрики F1;
- Модели прошли проверку на адекватность.

**В проекте использованы библиотеки:**
- pandas
- matplotlib
- seaborn
- sklearn
- catboost
- lightgbm
